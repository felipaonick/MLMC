# ğŸ§  Autoencoder: Compressione, Denoising e Pulizia di Testi Scannerizzati

## ğŸ“Œ Obiettivi della Esercitazione

1. ğŸŒ€ Comprimere dati MNIST (estraendo feature principali)
2. âŒ Ricostruire immagini a partire da dati **rumorosi**
3. ğŸ§¾ Pulire immagini scannerizzate con testo sporco da rumore fisico (es. macchie da bicchieri)

---

## ğŸ”§ Setup Iniziale: Importazione Librerie

* ğŸ“š NumPy, Matplotlib.pyplot
* ğŸ“¦ Dataset `MNIST` da Keras
* ğŸ§± Layers: `Conv2D`, `MaxPooling2D`, `UpSampling2D`, `BatchNormalization`
* ğŸ§ª Ottimizzatore: `Nadam`
* ğŸ–¼ï¸ Funzioni di preprocessing delle immagini (Keras)

---

## ğŸ—‚ï¸ Preparazione dei Dati

### ğŸ¨ Normalizzazione e Reshape

* Immagini reshape in `28x28x1`
* Valori normalizzati su scala `[0, 1]`

### ğŸŒªï¸ Aggiunta di Rumore

* Rumore aggiunto tramite:

  ```python
  noisy = original + 0.65 * np.random.normal(0, 1, shape)
  ```
* Clipping con `np.clip()` per mantenere i valori tra `0` e `1`

---

## ğŸ§  Costruzione dellâ€™Autoencoder

### ğŸ”„ Architettura Encoder (con Functional API)

* Input: `(28, 28, 1)`
* 2 blocchi convolutivi con:

  * `Conv2D (3x3) + ReLU + Padding='same'`
  * `MaxPooling2D`
  * `BatchNormalization`
* Output encoder: **rappresentazione latente** `7x7x64`

### ğŸ” Architettura Decoder (speculare)

* Uso di:

  * `Conv2D`
  * `UpSampling2D`
  * `BatchNormalization`
* Output finale:

  ```python
  Conv2D(filters=1, kernel_size=3x3, activation='sigmoid', padding='same')
  ```

  che da in output una immagine 28x28

---

## âš™ï¸ Addestramento del Modello

* ğŸ” Epoche: `100`
* ğŸ“¦ Batch Size: `1024`
* ğŸ§® Loss Function: `binary_crossentropy`
* ğŸ“‰ **Loss decrescente** fino a \~50 epoche, poi si appiattisce â†’ suggerisce possibile tuning del **learning rate**

---

## ğŸ” Analisi della Rappresentazione Latente

* Estrazione dei **primi 7 layer** (encoding puro)
* Visualizzazione delle feature map con `matplotlib`
* ğŸ‘€ Ogni pixel â†’ contiene **feature informative** usate per la ricostruzione
* Immagini piÃ¹ â€œsempliciâ€ (es. rapr. latente del numero 1) â†’ feature map piÃ¹ scure
  Immagini complesse (es. rapr. latente del numero 8) â†’ feature map piÃ¹ attive e quindi piÃ¹ chiare

---

## ğŸ“¸ Fase di Denoising: Risultati

### ğŸ”¹ Con Rumore 65%

* Immagini rumorose â†’ difficilmente leggibili
* Output dellâ€™autoencoder:

  * âœ¨ Ricostruzioni fedeli nel complesso
  * Alcuni errori marginali (es. 5 vs 6 ambigui)

### ğŸ”¸ Con Rumore 80%

* Molte immagini risultano illeggibili a occhio nudo ğŸ‘€
* Autoencoder riesce comunque a:

  * Recuperare struttura generale
  * Preservare molte feature
  * Alcuni errori di classificazione evidenti

---

## ğŸ§¾ Pulizia Testi Scannerizzati

### ğŸ“‚ Dataset OCR

* Directory:

  * `data.ocr/train`
  * `data.ocr/train_cleaned`
  * `data.ocr/test`
* ğŸ“¦ Caricamento immagini con `glob`

### ğŸ§¼ Preprocessing Immagini

* Resize a `(428, 548, 3)`
* Conversione a `float32`, normalizzazione su `[0, 1]`
* Costruzione di `numpy.ndarray` con shape corretta

### ğŸ§ª Dati Puliti vs Dati Sporchi

* Visualizzazione di:

  * ğŸ”¸ Immagine sporca (es. macchie caffÃ¨ â˜•)
  * ğŸ”¹ Immagine pulita 

---

## âœ… Considerazioni Finali

| Aspetto                     | Osservazione                                 |
| --------------------------- | -------------------------------------------- |
| ğŸ§  Rappresentazione Latente | Ben strutturata, anche in presenza di rumore |
| ğŸ“‰ Performance              | Buona perdita, migliorabile oltre 50 epoche  |
| ğŸ–¼ï¸ Ricostruzione OCR       | Funziona anche su immagini reali e degradate |
| ğŸ› ï¸ Architettura            | Encoder/Decoder speculari + normalizzazione  |
| ğŸ” Feature Map              | Intuibili da livello di attivazione visivo   |

---
